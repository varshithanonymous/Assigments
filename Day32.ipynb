{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wYgxCKXj0g1",
        "outputId": "06632a33-43ee-4f37-c60d-c92eefbfba58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to your text file: sample.txt\n",
            "Top 5 most frequent tokens:\n",
            "hello: 1\n",
            "im: 1\n",
            "varshith: 1\n",
            "from: 1\n",
            "aiml: 1\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def load_text(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def tokenize(text):\n",
        "    # Tokenize the text by removing punctuation and splitting into words\n",
        "    tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "    return tokens\n",
        "\n",
        "def calculate_term_frequency(tokens):\n",
        "    # Calculate the term frequency using Counter to count occurrences of each token\n",
        "    term_frequency = Counter(tokens)\n",
        "    return term_frequency\n",
        "\n",
        "def display_top_tokens(term_frequency, top_n=5):\n",
        "    # Display the top 'top_n' most frequent tokens\n",
        "    most_common = term_frequency.most_common(top_n)\n",
        "    print(f\"Top {top_n} most frequent tokens:\")\n",
        "    for token, freq in most_common:\n",
        "        print(f\"{token}: {freq}\")\n",
        "\n",
        "# Main function to load the file and process it\n",
        "def main(file_path):\n",
        "    text = load_text(file_path)\n",
        "    tokens = tokenize(text)\n",
        "    term_frequency = calculate_term_frequency(tokens)\n",
        "    display_top_tokens(term_frequency)\n",
        "\n",
        "# File path to the text file\n",
        "file_path = input(\"Enter the path to your text file: \")\n",
        "\n",
        "# Run the program\n",
        "main(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Q701Imyk4l6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}